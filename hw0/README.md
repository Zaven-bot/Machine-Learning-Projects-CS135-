## HW1: Regression, Cross-Validation, and Regularization <br>

> **Coding Tasks:** <br>
>> * Implemented the calculation of root mean squared error in performance_metrics.py. <br>
>> * Implemented the fit and predict methods for linear regression in LeastSquaresLinearRegression.py. <br>
>> * Implemented functions to randomly divide data into splits and estimate training and heldout error in cross_validation.py. <br>

> **Report Tasks:** <br>
>> * Discussed fitting linear regression models to polynomial feature transformations of the training set at various degrees. <br>
>> * Discussed select the best model based on validation set error. <br>
>> * Analyzed the effect of feature rescaling, interpret learned weight parameters, and observe trends in performance. <br>
>> * Analyze learned weight parameters and discuss the implications of regularization strength. <br>
>> * Introduce a "ridge" penalty to mitigate overfitting in complex models. <br>
>> * Select the best model based on validation set error with varying alpha values. <br>
>> * Compare the performance of different methods, including a baseline predictor, polynomial regression with fixed degree, and polynomial regression with selected degree and alpha. <br>
