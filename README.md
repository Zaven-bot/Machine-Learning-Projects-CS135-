# Machine-Learning-Projects-CS135-
This includes my work done in CS135 Intro To Machine Learning at Tufts University 2023-2024.

### HW0: Numerical Programming Fundamentals <br>
**Coding**: Implemented functions to split datasets into train and test sets, and to find the k-nearest neighbors using Euclidean distance. <br>
**Summary**: This assignment focused on fundamental numerical programming tasks, including data splitting and distance calculations. <br>

### HW1: Regression, Cross-Validation, and Regularization <br>
**Coding**: Implemented root mean squared error calculation, linear regression, and cross-validation functions. <br>
**Report**: Explored polynomial regression, regularization, and cross-validation techniques for model selection. <br>
**Summary**: Explored regression techniques, cross-validation, and regularization methods to understand their impact on model performance. <br>

### HW2: Evaluating Binary Classifiers and Implementing Logistic Regression <br>
**Coding**: Implemented functions to evaluate binary classifier performance metrics and to compute the loss for logistic regression. <br>
**Report**: Analyzed binary classifier performance metrics, evaluated logistic regression models, and explored different thresholding strategies. <br>
**Summary**: Explored evaluating binary classifiers and implementing logistic regression, focusing on performance metrics and thresholding strategies. <br>

### HW3: Neural Networks and Gradient Descent <br>
**Coding**: Implemented forward propagation for neural networks with and without hidden layers. <br>
**Report**: Evaluated multilayer perceptrons (MLPs) using different solvers and hidden layer sizes, analyzed training objective convexity, and compared batch size and step size performance. <br>
**Summary**: Explored neural networks and gradient descent, focusing on MLP implementation, solver options, and training performance analysis. <br>

### HW4: Trees and Random Forests <br>
**Coding**: Implemented decision tree prediction, tree node selection, and random forest training. <br>
**Report**: Explored decision trees and random forests for review classification, including hyperparameter tuning and performance analysis. <br>
**Summary**: Explored decision trees and random forests, focusing on prediction, hyperparameter tuning, and performance evaluation for review classification tasks. <br>
